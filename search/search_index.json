{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AWorld Developer Platform","text":"<p>Use the AWorld API to build stateful agents, complex workflows, and multi-agent systems that can learn and evolve. AWorld provides a robust framework for agent orchestration and reinforcement learning integration.</p>"},{"location":"#get-started","title":"Get started","text":"<p>Quickstart Build your first agent in 5 minutes with Python.</p> <p>Core concepts Understand Agents, Swarms, and how AWorld manages state.</p> <p>Guides Step-by-step instructions for memory design, tools, multi-agent systems, and training.</p>"},{"location":"#build-deploy-and-scale","title":"Build, deploy, and scale","text":"<p>Building Agents Working code examples for common use cases and agent patterns.</p> <p>Orchestration Learn how to build complex Workflows and Multi-Agent Systems.</p> <p>Training Integrate with Reinforcement Learning frameworks like Verl to train your agents.</p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>This guide will show you how to install AWorld and build your first agent.</p>"},{"location":"quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+</li> <li>Git</li> </ul>"},{"location":"quickstart/#installation","title":"Installation","text":"<p>Install AWorld directly from the source:</p> <pre><code>git clone https://github.com/inclusionAI/AWorld &amp;&amp; cd AWorld\npip install .\n</code></pre>"},{"location":"quickstart/#build-your-first-agent","title":"Build your first Agent","text":"<p>Let's create a simple agent named <code>my_agent</code>.</p>"},{"location":"quickstart/#1-basic-setup","title":"1. Basic Setup","text":"<p>Create a file named <code>hello_world.py</code> and add the following code:</p> <pre><code>from aworld.agents.llm_agent import Agent\n\n# Assign a name to your agent\nagent = Agent(name=\"my_agent\")\n\nprint(f\"Agent {agent.name} created successfully!\")\n</code></pre>"},{"location":"quickstart/#2-configure-llm","title":"2. Configure LLM","text":"<p>You can configure the LLM provider using environment variables. This is the quickest way to get started.</p> <pre><code>import os\nfrom aworld.agents.llm_agent import Agent\n\n# Set up LLM service using environment variables\nos.environ[\"LLM_PROVIDER\"] = \"openai\"  # Choose from: openai, anthropic, azure_openai\nos.environ[\"LLM_MODEL_NAME\"] = \"gpt-4\"\nos.environ[\"LLM_API_KEY\"] = \"your-api-key\"\n# os.environ[\"LLM_BASE_URL\"] = \"https://api.openai.com/v1\"  # Optional\n\nagent = Agent(name=\"my_agent\")\n</code></pre>"},{"location":"quickstart/#3-run-your-agent","title":"3. Run your Agent","text":"<p>You can now interact with your agent. (Assuming an interactive run method exists or adding a simple print to verify configuration).</p> <pre><code># Simple verification\nprint(f\"Agent '{agent.name}' is ready to use with {os.environ['LLM_MODEL_NAME']}.\")\n</code></pre>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you have a basic agent, learn how to:</p> <ul> <li>Customize your Agent with system prompts and configurations.</li> <li>Add Tools to give your agent capabilities.</li> <li>Build Workflows to chain multiple agents together.</li> </ul>"},{"location":"core_concepts/agents/","title":"Agents","text":"<p>In AWorld, an Agent is the fundamental building block of any system, whether it's a simple chatbot, a linear workflow, or a complex multi-agent system.</p>"},{"location":"core_concepts/agents/#what-is-an-agent","title":"What is an Agent?","text":"<p>An Agent in AWorld is a stateful entity that can: 1.  Observe its environment (<code>Observation</code>). 2.  Process information using an LLM or custom logic (<code>Policy</code>). 3.  Act by calling tools or sending messages (<code>Action</code>).</p> <p>The primary implementation provided is <code>llm_agent.Agent</code>, which wraps a Large Language Model to handle reasoning and decision-making.</p>"},{"location":"core_concepts/agents/#key-components","title":"Key Components","text":""},{"location":"core_concepts/agents/#1-configuration-agentconfig","title":"1. Configuration (<code>AgentConfig</code>)","text":"<p>Agents are highly configurable. You can define the LLM provider (OpenAI, Anthropic, etc.), model parameters, and API keys. This configuration can be individual per agent or shared via a <code>ModelConfig</code>.</p>"},{"location":"core_concepts/agents/#2-system-prompt","title":"2. System Prompt","text":"<p>The system prompt defines the agent's persona, constraints, and instructions. It sets the context for all interactions.</p>"},{"location":"core_concepts/agents/#3-tools","title":"3. Tools","text":"<p>Agents can be equipped with tools to interact with the outside world. AWorld supports: - Local Tools: Python functions decorated with <code>@be_tool</code>. - MCP Tools: Tools compliant with the Model Context Protocol (MCP). - Agent as Tool: Other agents can be registered as tools, allowing for hierarchical delegation.</p>"},{"location":"core_concepts/agents/#lifecycle","title":"Lifecycle","text":"<p>An agent's lifecycle involves receiving a <code>Message</code> or <code>Observation</code>, transforming it for the model, invoking the model, parsing the output, and executing actions. This entire loop is customizable via methods like <code>async_messages_transform</code>, <code>invoke_model</code>, and <code>async_post_run</code>.</p>"},{"location":"core_concepts/mas/","title":"Multi-Agent Systems (MAS)","text":"<p>While Workflows handle static processes, Multi-Agent Systems (MAS) in AWorld are designed for dynamic, real-time decision-making.</p>"},{"location":"core_concepts/mas/#dynamic-handoffs","title":"Dynamic Handoffs","text":"<p>In a MAS, the flow of execution is not hardcoded. Instead, agents decide at runtime who to talk to next based on the conversation context. This is achieved using the <code>GraphBuildType.HANDOFF</code> mode in a <code>Swarm</code>.</p> <ul> <li>Agent A receives a query.</li> <li>Agent A decides it needs help from Agent B.</li> <li>Agent A \"hands off\" the task to Agent B.</li> <li>Agent B performs the task and may hand back to A or forward to Agent C.</li> </ul>"},{"location":"core_concepts/mas/#event-driven-architecture","title":"Event-Driven Architecture","text":"<p>MAS in AWorld relies on an event mechanism. The output of one agent serves as the input for the next, facilitating complex interaction patterns.</p>"},{"location":"core_concepts/mas/#routing-topology","title":"Routing &amp; Topology","text":"<p>Even in a dynamic system, you define a Topology\u2014a set of allowed connections. For example, you might allow the \"Manager\" to talk to \"Worker A\" and \"Worker B\", but prevent \"Worker A\" from talking directly to \"Worker B\".</p> <p>AWorld supports complex routing logic, allowing you to override default behaviors and implement custom routing protocols (e.g., Round Robin, Broadcast, or Semantic Routing).</p>"},{"location":"core_concepts/workflows/","title":"Workflows","text":"<p>Workflows in AWorld represent static, pre-defined execution flows. They are used when the sequence of operations is deterministic and known in advance.</p>"},{"location":"core_concepts/workflows/#the-swarm-concept","title":"The Swarm Concept","text":"<p>AWorld uses the concept of a <code>Swarm</code> to manage collections of agents. For workflows, a Swarm is defined with a specific topology that dictates how data flows between agents.</p>"},{"location":"core_concepts/workflows/#types-of-workflows","title":"Types of Workflows","text":"<p>AWorld supports classic graph syntaxes to describe workflows:</p>"},{"location":"core_concepts/workflows/#sequential","title":"Sequential","text":"<p>A linear pipeline where the output of one agent becomes the input of the next. <code>Agent A -&gt; Agent B -&gt; Agent C</code></p>"},{"location":"core_concepts/workflows/#parallel-with-barrier","title":"Parallel with Barrier","text":"<p>Multiple agents execute simultaneously, and a subsequent agent waits for all of them to finish before proceeding. This is useful for tasks like \"researching multiple topics at once and then summarizing them.\"</p>"},{"location":"core_concepts/workflows/#parallel-multi-path","title":"Parallel Multi-Path","text":"<p>A mix of sequential and parallel paths. An agent can distribute work to multiple downstream agents, which then converge later.</p>"},{"location":"core_concepts/workflows/#task-native-workflow","title":"Task Native Workflow","text":"<p>For scenarios requiring strict isolation of runtimes and environments (e.g., distributed systems), AWorld provides Task Native Workflows. These wrap agents in <code>Task</code> objects and manage execution dependencies explicitly.</p>"},{"location":"guides/building_agents/","title":"Building Agents","text":"<p>This guide provides detailed instructions on how to configure, customize, and extend Agents in AWorld.</p>"},{"location":"guides/building_agents/#configuration","title":"Configuration","text":""},{"location":"guides/building_agents/#using-environment-variables","title":"Using Environment Variables","text":"<p>The simplest way to configure an agent is via environment variables.</p> <pre><code>import os\nfrom aworld.agents.llm_agent import Agent\n\nos.environ[\"LLM_PROVIDER\"] = \"openai\"\nos.environ[\"LLM_MODEL_NAME\"] = \"gpt-4\"\nos.environ[\"LLM_API_KEY\"] = \"sk-...\"\n# os.environ[\"LLM_BASE_URL\"] = \"...\" # Optional\n\nagent = Agent(name=\"simple_agent\")\n</code></pre>"},{"location":"guides/building_agents/#using-agentconfig","title":"Using AgentConfig","text":"<p>For more control, use <code>AgentConfig</code>.</p> <pre><code>from aworld.agents.llm_agent import Agent\nfrom aworld.config.conf import AgentConfig\n\nagent_config = AgentConfig(\n    llm_provider=\"openai\",\n    llm_model_name=\"gpt-4\",\n    llm_api_key=\"sk-...\"\n)\n\nagent = Agent(name=\"configured_agent\", conf=agent_config)\n</code></pre>"},{"location":"guides/building_agents/#shared-model-configuration","title":"Shared Model Configuration","text":"<p>If multiple agents share the same LLM settings, use <code>ModelConfig</code>.</p> <pre><code>from aworld.config.conf import AgentConfig, ModelConfig\n\nmodel_config = ModelConfig(\n    llm_provider=\"openai\",\n    llm_model_name=\"gpt-4\",\n    llm_api_key=\"sk-...\"\n)\n\nagent_config = AgentConfig(llm_config=model_config)\nagent = Agent(name=\"shared_agent\", conf=agent_config)\n</code></pre>"},{"location":"guides/building_agents/#system-prompts","title":"System Prompts","text":"<p>Define the agent's behavior using the <code>system_prompt</code> parameter.</p> <pre><code>system_prompt = \"\"\"You are a helpful AI assistant.\nYou should be polite, accurate, and provide clear explanations.\"\"\"\n\nagent = Agent(\n    name=\"polite_agent\",\n    conf=agent_config,\n    system_prompt=system_prompt\n)\n</code></pre>"},{"location":"guides/building_agents/#configuring-tools","title":"Configuring Tools","text":""},{"location":"guides/building_agents/#local-tools","title":"Local Tools","text":"<p>Turn Python functions into tools using the <code>@be_tool</code> decorator.</p> <pre><code>from aworld.core.tool.func_to_tool import be_tool\n\n@be_tool(tool_name='greeting_tool', tool_desc=\"Returns a hello message\")\ndef greeting_tool() -&gt; str:\n    return \"Hello, world!\"\n\nagent = Agent(\n    name=\"tool_agent\",\n    conf=agent_config,\n    tool_names=['greeting_tool']\n)\n</code></pre>"},{"location":"guides/building_agents/#mcp-tools","title":"MCP Tools","text":"<p>Connect to Model Context Protocol (MCP) servers.</p> <pre><code>mcp_config = {\n    \"mcpServers\": {\n        \"Filesystem\": {\n            \"type\": \"stdio\",\n            \"command\": \"python\",\n            \"args\": [\"path/to/mcp_server.py\"],\n        },\n    }\n}\n\nagent = Agent(\n    name=\"mcp_agent\",\n    conf=agent_config,\n    mcp_servers=[\"Filesystem\"],\n    mcp_config=mcp_config\n)\n</code></pre>"},{"location":"guides/building_agents/#agent-as-tool","title":"Agent as Tool","text":"<p>An agent can use another agent as a tool.</p> <pre><code>worker_agent = Agent(name=\"worker\", conf=agent_config)\n\nmanager_agent = Agent(\n    name=\"manager\",\n    conf=agent_config,\n    agent_names=['worker']\n)\n</code></pre>"},{"location":"guides/building_agents/#customization","title":"Customization","text":"<p>AWorld allows you to override core agent behaviors.</p>"},{"location":"guides/building_agents/#custom-observation","title":"Custom Observation","text":"<p>Modify <code>init_observation</code> to enrich input data.</p> <pre><code>async def init_observation(self, observation: Observation) -&gt; Observation:\n    observation.metadata = {\"timestamp\": time.time()}\n    return observation\n</code></pre>"},{"location":"guides/building_agents/#custom-model-logic","title":"Custom Model Logic","text":"<p>Override <code>invoke_model</code> to use non-LLM logic or custom models.</p> <pre><code>async def invoke_model(self, messages, **kwargs) -&gt; ModelResponse:\n    if self.use_custom_logic:\n         return ModelResponse(content=\"Custom logic result\", model=\"custom\")\n    return await self.llm_client.chat_completion(messages)\n</code></pre>"},{"location":"guides/building_agents/#custom-output-parser","title":"Custom Output Parser","text":"<p>Implement <code>ModelOutputParser</code> to handle custom model responses.</p> <pre><code>class CustomParser(ModelOutputParser):\n    async def parse(self, resp: ModelResponse, **kwargs) -&gt; AgentResult:\n        # Custom parsing logic\n        return AgentResult(content=resp.content)\n\nagent = Agent(..., model_output_parser=CustomParser())\n</code></pre>"},{"location":"guides/orchestration/","title":"Orchestration: Workflows &amp; MAS","text":"<p>This guide covers how to connect multiple agents to build Workflows and Multi-Agent Systems (MAS).</p>"},{"location":"guides/orchestration/#workflows-static-topology","title":"Workflows (Static Topology)","text":"<p>Workflows are useful for deterministic processes.</p>"},{"location":"guides/orchestration/#sequential","title":"Sequential","text":"<p>Execute agents in a strict order: Agent A -&gt; Agent B.</p> <pre><code>from aworld.core.agent.swarm import Swarm\nfrom aworld.runner import Runners\n\n# Define the sequence\nswarm = Swarm([(agent1, agent2), (agent2, agent3)], root_agent=[agent1])\nRunners.run(input=\"start\", swarm=swarm)\n</code></pre>"},{"location":"guides/orchestration/#parallel","title":"Parallel","text":"<p>Agents run simultaneously, synchronizing at a specific point.</p> <pre><code># agent1 and agent2 run in parallel, agent3 waits for both\nswarm = Swarm([(agent1, agent3), (agent2, agent3)], root_agent=[agent1, agent2])\nRunners.run(input=\"start\", swarm=swarm)\n</code></pre>"},{"location":"guides/orchestration/#multi-agent-systems-dynamic-handoff","title":"Multi-Agent Systems (Dynamic Handoff)","text":"<p>MAS allows agents to decide the control flow dynamically.</p>"},{"location":"guides/orchestration/#basic-setup","title":"Basic Setup","text":"<p>Use <code>GraphBuildType.HANDOFF</code> to enable dynamic routing.</p> <pre><code>from aworld.core.agent.swarm import Swarm, GraphBuildType\n\n# Define allowed communication paths\nswarm = Swarm(\n    topology=[(agent1, agent2), (agent2, agent3), (agent1, agent3)],\n    build_type=GraphBuildType.HANDOFF,\n    root_agent=[agent1]\n)\n\nRunners.run(input=\"your question\", swarm=swarm)\n</code></pre>"},{"location":"guides/orchestration/#hybrid-systems","title":"Hybrid Systems","text":"<p>You can nest Swarms to combine static workflows with dynamic MAS.</p> <pre><code># MAS handles complex planning\nmas_team = Swarm(..., build_type=GraphBuildType.HANDOFF)\n\n# Workflow wraps the MAS team\nworkflow = Swarm(\n    topology=[(preprocess_agent, mas_team), (mas_team, summary_agent)],\n    root_agent=[preprocess_agent]\n)\n</code></pre>"},{"location":"guides/orchestration/#advanced-routing","title":"Advanced Routing","text":""},{"location":"guides/orchestration/#custom-handlers","title":"Custom Handlers","text":"<p>You can implement custom event handlers to control exactly how messages are routed between agents.</p> <pre><code>from aworld.runners import HandlerFactory\nfrom aworld.runners.handler import DefaultHandler\n\n@HandlerFactory.register(name=\"custom_router\")\nclass CustomRouter(DefaultHandler):\n    async def _do_handle(self, message):\n        # Your custom routing logic here\n        pass\n\nagent = Agent(..., event_handler_name=\"custom_router\")\n</code></pre>"},{"location":"guides/orchestration/#examples-react-and-plan-execute","title":"Examples: ReAct and Plan-Execute","text":"<p>AWorld includes built-in patterns for complex reasoning.</p> <ul> <li>ReAct: Standard Reason-Act loop.</li> <li>Plan-Execute: Separates planning from execution, allowing parallel execution of planned steps.</li> </ul>"},{"location":"guides/training/","title":"Training Agents","text":"<p>AWorld allows you to train agents using Reinforcement Learning (RL) by integrating with frameworks like Verl.</p>"},{"location":"guides/training/#architecture","title":"Architecture","text":"<p>The training pipeline consists of: 1.  Environment (<code>env</code>): The problem space (e.g., Gaia benchmark). 2.  Agent: Your AWorld agent. 3.  Adapter: Bridges AWorld Agent with the training framework. 4.  Training Framework (<code>verl</code>): Manages the RL loop (PPO, etc.).</p>"},{"location":"guides/training/#environment-setup","title":"Environment Setup","text":""},{"location":"guides/training/#1-requirements","title":"1. Requirements","text":"<ul> <li>Linux (recommended) with NVIDIA GPU.</li> <li>Docker &amp; Nvidia Container Toolkit.</li> <li>Python 3.11+.</li> </ul>"},{"location":"guides/training/#2-launch-gaia-environment","title":"2. Launch Gaia Environment","text":"<p>AWorld provides a dockerized environment for the Gaia benchmark.</p> <p><pre><code>cd ~/AWorld/env\nsh run-local.sh\n</code></pre> This starts an MCP server at <code>http://localhost:8000/mcp</code>.</p>"},{"location":"guides/training/#building-a-trainable-agent","title":"Building a Trainable Agent","text":"<p>To train an agent, you need to implement a custom <code>AgentLoop</code>.</p> <pre><code>from train.adapter.verl.aworld_agent_loop import AworldAgentLoop\n\nclass MyTrainableLoop(AworldAgentLoop):\n    def build_agents(self):\n        # Configure your agent to use the training environment's LLM\n        return Agent(\n            name=\"trainable_agent\",\n            conf=AgentConfig(\n                llm_base_url=self.get_llm_server_address(),\n                llm_model_name=self.get_llm_server_model_name(),\n                llm_api_key=\"dummy\"\n            ),\n            # Connect to the environment's tools\n            mcp_config=self.env_config,\n            mcp_servers=self.env_servers\n        )\n</code></pre>"},{"location":"guides/training/#running-the-training","title":"Running the Training","text":""},{"location":"guides/training/#1-reward-function","title":"1. Reward Function","text":"<p>Define a reward function to evaluate your agent's performance.</p> <pre><code>def my_reward_func(data_source, solution, ground_truth):\n    if solution == ground_truth:\n        return 1.0\n    return 0.0\n</code></pre>"},{"location":"guides/training/#2-configuration-launch","title":"2. Configuration &amp; Launch","text":"<p>Update <code>agent.yaml</code> to point to your <code>MyTrainableLoop</code> and run the training script.</p> <pre><code># Example command (simplified)\nbash run.sh \\\n    agent_loop_config_path=path/to/agent.yaml \\\n    reward_fn_name=my_reward_func\n</code></pre> <p>See the full <code>run.sh</code> in the <code>train/examples</code> directory for all hyperparameters (learning rate, batch size, etc.).</p>"}]}